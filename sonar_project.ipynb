{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras import models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "\n",
       "   0.0090  0.0032  R  \n",
       "0  0.0052  0.0044  R  \n",
       "1  0.0095  0.0078  R  \n",
       "2  0.0040  0.0117  R  \n",
       "3  0.0107  0.0094  R  \n",
       "4  0.0051  0.0062  R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('sonar.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:60].values.astype(float)\n",
    "y = data.iloc[:,60].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding our labels\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting our data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing our data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Umair khan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#adding the input and first hidden layer\n",
    "model = models.Sequential()\n",
    "model.add(Dense(16,activation = 'relu',input_shape=(60,)))\n",
    "\n",
    "#adding second hidden layer\n",
    "model.add(Dense(16,activation = 'relu'))\n",
    "\n",
    "#addng output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Umair khan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 2s 11ms/sample - loss: 0.7015 - acc: 0.5024\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 261us/sample - loss: 0.6964 - acc: 0.5362\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 222us/sample - loss: 0.6930 - acc: 0.5411\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 483us/sample - loss: 0.6899 - acc: 0.5652\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 169us/sample - loss: 0.6878 - acc: 0.5604\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 280us/sample - loss: 0.6852 - acc: 0.5604\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 266us/sample - loss: 0.6827 - acc: 0.5652\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 473us/sample - loss: 0.6804 - acc: 0.5700\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 454us/sample - loss: 0.6781 - acc: 0.5749\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 251us/sample - loss: 0.6764 - acc: 0.5700\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 280us/sample - loss: 0.6740 - acc: 0.5749\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 406us/sample - loss: 0.6725 - acc: 0.5894\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 498us/sample - loss: 0.6702 - acc: 0.5894\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 333us/sample - loss: 0.6680 - acc: 0.6039\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 188us/sample - loss: 0.6654 - acc: 0.5990\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 237us/sample - loss: 0.6627 - acc: 0.5942\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 261us/sample - loss: 0.6603 - acc: 0.6184\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 271us/sample - loss: 0.6565 - acc: 0.6425\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 343us/sample - loss: 0.6527 - acc: 0.6522\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 300us/sample - loss: 0.6471 - acc: 0.6522\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 454us/sample - loss: 0.6422 - acc: 0.6763\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 174us/sample - loss: 0.6394 - acc: 0.6812\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 92us/sample - loss: 0.6330 - acc: 0.6957\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 92us/sample - loss: 0.6245 - acc: 0.6957\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 97us/sample - loss: 0.6183 - acc: 0.7005\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 97us/sample - loss: 0.6117 - acc: 0.7150\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 87us/sample - loss: 0.6046 - acc: 0.7246\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 131us/sample - loss: 0.5979 - acc: 0.7343\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 87us/sample - loss: 0.5919 - acc: 0.7343\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.5847 - acc: 0.7488\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 261us/sample - loss: 0.5760 - acc: 0.7391\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 333us/sample - loss: 0.5684 - acc: 0.7536\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 357us/sample - loss: 0.5618 - acc: 0.7778\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 686us/sample - loss: 0.5534 - acc: 0.7729\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 319us/sample - loss: 0.5472 - acc: 0.7681\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 290us/sample - loss: 0.5440 - acc: 0.7874\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - ETA: 0s - loss: 0.5448 - acc: 0.718 - 0s 425us/sample - loss: 0.5381 - acc: 0.7826\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 913us/sample - loss: 0.5287 - acc: 0.7971\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 430us/sample - loss: 0.5201 - acc: 0.7585\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 261us/sample - loss: 0.5128 - acc: 0.7874\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 502us/sample - loss: 0.5075 - acc: 0.7971\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 517us/sample - loss: 0.5029 - acc: 0.8116\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 498us/sample - loss: 0.4998 - acc: 0.7826\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.4913 - acc: 0.8068\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 2ms/sample - loss: 0.4857 - acc: 0.7874 0s - loss: 0.4950 - acc: 0.78\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 787us/sample - loss: 0.4799 - acc: 0.7923\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 657us/sample - loss: 0.4747 - acc: 0.8019\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 589us/sample - loss: 0.4720 - acc: 0.7923\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 0s 734us/sample - loss: 0.4660 - acc: 0.8068\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 705us/sample - loss: 0.4634 - acc: 0.8019\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 763us/sample - loss: 0.4574 - acc: 0.8068\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 459us/sample - loss: 0.4547 - acc: 0.8116\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 754us/sample - loss: 0.4541 - acc: 0.8019\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 807us/sample - loss: 0.4499 - acc: 0.8019\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 647us/sample - loss: 0.4414 - acc: 0.8213\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 865us/sample - loss: 0.4387 - acc: 0.8164\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 865us/sample - loss: 0.4364 - acc: 0.8164\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 879us/sample - loss: 0.4322 - acc: 0.8164\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 633us/sample - loss: 0.4295 - acc: 0.8309\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 928us/sample - loss: 0.4266 - acc: 0.8309\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 643us/sample - loss: 0.4238 - acc: 0.8309\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.4213 - acc: 0.8261\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 763us/sample - loss: 0.4175 - acc: 0.8309\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 662us/sample - loss: 0.4167 - acc: 0.8068\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 831us/sample - loss: 0.4161 - acc: 0.8019\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 836us/sample - loss: 0.4128 - acc: 0.8116\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.4087 - acc: 0.8261\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 1ms/sample - loss: 0.4058 - acc: 0.8213\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 865us/sample - loss: 0.4046 - acc: 0.8309\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 473us/sample - loss: 0.4069 - acc: 0.8406\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 430us/sample - loss: 0.4037 - acc: 0.8357\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 0s 517us/sample - loss: 0.3981 - acc: 0.8309\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 517us/sample - loss: 0.3958 - acc: 0.8213\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 440us/sample - loss: 0.3941 - acc: 0.8261\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 546us/sample - loss: 0.3918 - acc: 0.8261\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 618us/sample - loss: 0.3889 - acc: 0.8406\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 502us/sample - loss: 0.3894 - acc: 0.8406\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 575us/sample - loss: 0.3885 - acc: 0.8213\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 415us/sample - loss: 0.3868 - acc: 0.8164\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 386us/sample - loss: 0.3848 - acc: 0.8261\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 0s 338us/sample - loss: 0.3797 - acc: 0.8406\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 319us/sample - loss: 0.3788 - acc: 0.8406\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 184us/sample - loss: 0.3748 - acc: 0.8357\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 217us/sample - loss: 0.3748 - acc: 0.8406\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 266us/sample - loss: 0.3760 - acc: 0.8213\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 213us/sample - loss: 0.3710 - acc: 0.8357\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 237us/sample - loss: 0.3686 - acc: 0.8406\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 155us/sample - loss: 0.3660 - acc: 0.8406\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 309us/sample - loss: 0.3643 - acc: 0.8454\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 242us/sample - loss: 0.3640 - acc: 0.8502\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 217us/sample - loss: 0.3599 - acc: 0.8454\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 188us/sample - loss: 0.3587 - acc: 0.8502\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 213us/sample - loss: 0.3575 - acc: 0.8551\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 242us/sample - loss: 0.3553 - acc: 0.8551\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 0s 155us/sample - loss: 0.3541 - acc: 0.8502\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 319us/sample - loss: 0.3518 - acc: 0.8502\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 227us/sample - loss: 0.3498 - acc: 0.8502\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 159us/sample - loss: 0.3479 - acc: 0.8502\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 242us/sample - loss: 0.3460 - acc: 0.8502\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 198us/sample - loss: 0.3431 - acc: 0.8599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e981db4cf8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,batch_size = 64,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380952380952381"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (11+20)/(11+11+20)\n",
    "print('the accuracy is ,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
